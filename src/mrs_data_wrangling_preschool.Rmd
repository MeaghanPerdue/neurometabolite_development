---
title: "preschool_data_wrangling"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(root.dir = '/Users/meaghan/OneDrive - University of Calgary/Preschool_data/MRS')
library(reticulate)
```

## Organize data for MRS project

Import data from old tracking sheet and reduce to kids with MRS & relevant columns
```{python}
import numpy as np
import pandas as pd 

df = pd.read_csv("/Users/meaghan/OneDrive - University of Calgary/Preschool_data/preschool_mri_data_sheet.csv")

mrs = df.loc[df["spec"] == '1', ['study_code','subj_id', 'spec_id', 'date_scan', 'hand', 'female', 'mri_age_y', 'demographics', 'pp_data', 'sn_data', 'spec', 'spec_location', 't1', 't1_quality', 'dti_b750', 'dti_b2000', 'dti750_te', 'notes']]

```

Recode t1_quality from text to numeric (1=good, 2=medium, 3=bad) & convert date_scan to datetime format
```{python}
mrs = mrs.replace({"good": 1, "medium": 2, "bad":3, "good ":1, "medium ":2, "bad ":3})

mrs['date_scan_dt'] = pd.to_datetime(mrs['date_scan'])
mrs['date_scan'] = mrs['date_scan_dt'].dt.date
```

Then import data from REDCap export (2019-present), rename variables to match mrs dataframe and reduce to kids with MRS & relevant columns & convert date format to datetime format
```{python}
df2 = pd.read_csv("/Users/meaghan/OneDrive - University of Calgary/Preschool_data/redcap_report_mri_data_oct1921.csv")

df2 = df2.rename(columns={"meta_subj_id": "subj_id", "mri_studycode": "study_code", "mri_date": "date_scan", "mri_sequence___1": "dti_b750", "mri_sequence___2": "t1", "mri_sequence___3": "t2_star", "mri_sequence___4": "asl", "mri_sequence___5": "fmri", "mri_sequence___6": "t2_anat", "mri_sequence___7": "ihmt", "mri_sequence___8": "spec", "mri_sequence___9": "dti_b2000", "mri_sequence___10": "wm_dti_b900_adol", "mri_sequence___11": "wm_dti_b2000_adol", "mri_te_value_750": "dti750_te", "mri_t1_dq":"t1_quality", "mri_spec_id": "spec_id", "mri_spec_location": "spec_location"})

mrs2 = df2.loc[df2["spec"] == 1, ['study_code', 'subj_id', 'spec_id', 'date_scan', 'mri_age_y', 'spec', 'spec_location', 't1', 't1_quality', 'dti_b750', 'dti_b2000', 'dti750_te']]

mrs2['date_scan_dt'] = pd.to_datetime(mrs2['date_scan'], yearfirst=True)
mrs2['date_scan'] = mrs2['date_scan_dt'].dt.date
```

Merge mrs and mrs2 dataframes, clean up, and create new separate columns indicating yes/no for acquisition of ACG and LAG voxels, count total data sets per voxel and how many subjects have MRS data for each voxel
```{python}
mrs_all = mrs.append(mrs2)

mrs_all = mrs_all.replace({"ACG": 1, "LAG": 2, "LAG, ACG": 3, "LAG and ACG": 3})

mrs_all['spec_location'].value_counts()

mrs_all.loc[(mrs_all['spec_location'] == 1) | (mrs_all['spec_location'] == 3), 'spec_acg'] = 1
mrs_all.loc[(mrs_all['spec_location'] == 2), 'spec_acg'] = 0

mrs_all.loc[(mrs_all['spec_location'] == 2) | (mrs_all['spec_location'] == 3), 'spec_lag'] = 1
mrs_all.loc[(mrs_all['spec_location'] == 1), 'spec_lag'] = 0

mrs_all['spec_acg'].value_counts()
mrs_all['spec_lag'].value_counts()

mrs_all.groupby('spec_acg')['subj_id'].nunique()
mrs_all.groupby('spec_lag')['subj_id'].nunique()
```
Save mrs_all dataframe to .csv
```{python}
mrs_all.to_csv("/Users/meaghan/OneDrive - University of Calgary/Preschool_data/MRS/data/mrs_data_summary_Oct2021.csv", index=False)
```


Create separate data frames for ACG and LAG data and write to .csv
```{python}
mrs_acg = mrs_all.query('spec_acg == 1')
mrs_acg.to_csv("/Users/meaghan/OneDrive - University of Calgary/Preschool_data/MRS/data/mrs_data_ACG_Oct2021.csv", index=False)

mrs_lag = mrs_all.query('spec_lag == 1')
mrs_lag.to_csv("/Users/meaghan/OneDrive - University of Calgary/Preschool_data/MRS/data/mrs_data_LAG_Oct2021.csv", index=False)
```

Age range per voxel location
```{python}
mrs_acg['mri_age_y'].min()
mrs_acg['mri_age_y'].max()

mrs_lag['mri_age_y'].min()
mrs_lag['mri_age_y'].max()

```

Create variable to track data collected after ISMRM abstract and check count
```{python}
mrs_all.loc[(mrs_all['date_scan_dt'] > '2019-07-09'), 'after_jul092019'] = 1
mrs_all.loc[(mrs_all['date_scan_dt'] <= '2019-07-09'), 'after_jul092019'] = 0

mrs_all['after_jul092019'].value_counts()
mrs_all.groupby('after_jul092019')['subj_id'].nunique()

mrs_all.to_csv("/Users/meaghan/OneDrive - University of Calgary/Preschool_data/MRS/data/mrs_data_summary_Oct2021.csv", index=False)
```

Create list of subject folders for downloading pfiles
first create a column of the folder name prefix and a separator
make sure mrs_lag is pulled from code as above (reading in from .csv gets the date time format wrong for the string we need)
concatenate columns to produce folder name where p file is located & write to a .txt file
```{python}

mrs_lag['pfile_prefix'] = "SPECT-EXAM"
mrs_lag['sep'] = "-"

mrs_lag['pfile_path'] = mrs_lag['pfile_prefix'].map(str) + mrs_lag['spec_id'].astype(str).str.split('.', expand = True)[0] + mrs_lag['sep'].map(str) + mrs_lag['date_scan_dt'].astype(str).str.split(' ', expand = True)[0]

pfile_path_lag=mrs_lag['pfile_path']
pfile_path_lag=pfile_path_lag[~pfile_path_lag.str.contains("nan")]

pfile_path_lag.to_csv("/Users/meaghan/OneDrive - University of Calgary/Preschool_data/MRS/data/mrs_lag_pfile_dir.txt", sep ='\t', header=False, index=False)
```

